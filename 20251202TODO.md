# 20251202TODO.md - The Ladder Project Master Document

**Date**: 2025-12-02
**Purpose**: Complete documentation for training an AI orchestrator to discover the Bitcoin puzzle ladder structure
**Philosophy**: Stop trying to solve it manually - train local AI to discover the pattern itself

---

## Table of Contents

1. [Project Origin Story](#1-project-origin-story)
2. [The Problem We're Solving](#2-the-problem-were-solving)
3. [What We've Discovered So Far](#3-what-weve-discovered-so-far)
4. [Two Competing Models](#4-two-competing-models)
5. [The Current Contradiction](#5-the-current-contradiction)
6. [Working Scripts & Tools](#6-working-scripts--tools)
7. [What Works (Proven)](#7-what-works-proven)
8. [What Doesn't Work Yet](#8-what-doesnt-work-yet)
9. [Why We're Not Getting It Right](#9-why-were-not-getting-it-right)
10. [The AI Orchestrator Approach](#10-the-ai-orchestrator-approach)
11. [Training Strategy](#11-training-strategy)
12. [Tools the AI Needs](#12-tools-the-ai-needs)
13. [Success Criteria](#13-success-criteria)
14. [Action Items](#14-action-items)

---

## 1. Project Origin Story

### The Bitcoin Puzzle Challenge

In 2015, someone created a series of 160 Bitcoin addresses with increasing amounts of BTC. Each address was generated from a private key with a specific bit length:

- Puzzle 1: 1-bit key (trivial)
- Puzzle 2: 2-bit key
- ...
- Puzzle 160: 160-bit key (full Bitcoin key space)

The keys for puzzles 1-70 have been publicly solved. Additionally, "bridge" puzzles at positions 75, 80, 85, 90, 95 (and more) have been solved.

### Our Hypothesis

These puzzles are NOT random. They were **engineered** using a mathematical formula. If we discover that formula, we can:
1. Reproduce all known puzzle keys exactly
2. Generate missing puzzle keys (71-74, 76-79, etc.)
3. Potentially solve puzzles up to 160

### How We Started

1. **Collected data**: All known puzzle keys (1-70 + bridges) in `data/btc_puzzle_1_160_full.csv`
2. **Analyzed patterns**: Found that keys evolve lane-by-lane (16 independent bytes)
3. **Applied ML**: Used PySR (symbolic regression) to discover formulas
4. **Built calibration**: Created drift tables that achieve 100% accuracy on puzzles 1-70

---

## 2. The Problem We're Solving

### Primary Question

**What is the mathematical formula that generates Bitcoin puzzle keys?**

### Constraints

1. **Must be exact**: 100% accuracy (byte-for-byte identical)
2. **Must be mathematical**: Pure formula, no lookup tables
3. **Must be forward-generating**: Start from puzzle 1, generate sequentially
4. **Must explain bridges**: The bridge puzzles (75, 80, 85, 90, 95) must fit the same pattern

### Why This Matters

- If it's truly random: No formula exists, project ends
- If it's engineered: Formula exists and is discoverable
- The existence of bridges suggests engineering (someone solved them using math, not brute force)

---

## 3. What We've Discovered So Far

### The Half-Block Structure

Each 32-byte private key is processed as **16 independent lanes** (bytes), with the formula operating on the **second half** (bytes 16-31) stored in **little-endian** format.

### The General Formula

```python
X_{k+1}[lane] = f(X_k[lane], A[lane], drift[lane]) mod 256
```

Where:
- `X_k[lane]`: Byte value at lane for puzzle k
- `A[lane]`: Multiplicative coefficient for that lane
- `drift[lane]`: Additive term (varies per transition or constant)

### The A Coefficients (Discovered)

```python
A = [1, 91, 1, 1, 1, 169, 1, 1, 1, 32, 1, 1, 1, 182, 1, 1]
```

Most lanes have A=1 (simple addition), but lanes 1, 5, 9, 13 have special multipliers.

---

## 4. Two Competing Models

### Model A: PySR Discovery (Experiment 01)

**Formula**:
```python
X_{k+1}[lane] = X_k[lane]^n mod 256

where n = [3, 2, 3, 2, 2, 3, 0, 2, 2, 3, 3, 2, 2, 2, 2, 3]
```

**Claims**:
- 100% accuracy on puzzles 1-70
- 100% accuracy on bridges 75, 80, 85, 90, 95
- No drift terms needed
- Simple polynomial recurrence

**Evidence**: `experiments/01-pysr-symbolic-regression/PROOF.md`

### Model B: Calibration + Drift (Experiment 05)

**Formula**:
```python
X_{k+1}[lane] = (A[lane]^4 * X_k[lane] + drift[k→k+1][lane]) mod 256
```

**Claims**:
- 100% accuracy on puzzles 1-70 (with corrected calibration)
- Per-transition drift values required
- Cryptographic validation working

**Evidence**: `experiments/05-ai-learns-ladder/VALIDATION_SUCCESS_2025-12-02.md`

---

## 5. The Current Contradiction

### The Problem

**Model A** (PySR) claims:
- Simple x², x³ formula with NO drift
- Works perfectly on 1-70 and bridges

**Model B** (Calibration) claims:
- Requires per-transition drift values
- Drift patterns are complex and unpredictable
- Cannot extend beyond puzzle 70 without knowing future drifts

### Why Can't Both Be True?

If Model A truly works with just exponents, then:
- Drift should be 0 everywhere
- The formula should trivially extend to 71-95

But Model B analysis shows:
- Bridges 70→75 have non-zero total drift
- Lanes 10-15 start showing drift after puzzle 80-85

### What Needs Investigation

1. **Re-test Model A**: Does PySR formula REALLY predict bridges correctly?
2. **Reconcile**: Are these the same formula expressed differently?
3. **Find the truth**: Which model actually generates correct Bitcoin addresses?

---

## 6. Working Scripts & Tools

### Data & Calibration

| Script | Purpose | Status |
|--------|---------|--------|
| `data/btc_puzzle_1_160_full.csv` | Source truth (all known keys) | ✅ Complete |
| `out/ladder_calib_CORRECTED.json` | Calibration with drift values | ✅ 100% on 1-70 |

### Experiment 01: PySR Symbolic Regression

| Script | Purpose | Status |
|--------|---------|--------|
| `scripts/prepare_data.py` | Split data into train/val/test | ✅ Working |
| `scripts/train_all_lanes.py` | Train PySR on all 16 lanes | ✅ Working |
| `scripts/extract_coefficients.py` | Extract discovered patterns | ✅ Working |
| `scripts/validate_formulas.py` | Validate on all datasets | ✅ Working |
| `scripts/verify_against_bitcoin_keys.py` | Bitcoin key verification | ✅ Claims 100% |

### Experiment 05: AI Learns Ladder

| Script | Purpose | Status |
|--------|---------|--------|
| `validate_full_process.py` | Full end-to-end validation | ✅ 100% on 1-70 |
| `recompute_calibration.py` | Recompute drift from CSV | ✅ Working |
| `crypto_validator.py` | Bitcoin address derivation | ✅ Working |
| `drift_neural_network.py` | Train drift predictor | ✅ 91.39% accuracy |
| `compute_missing_drifts.py` | C_0 from bridges | ✅ Working |

### Validation Tools

| Script | Purpose | Status |
|--------|---------|--------|
| `crypto_validator.py` | ECDSA + SHA256 + RIPEMD160 + Base58Check | ✅ Working |
| `test_address_derivation.py` | Test Bitcoin address generation | ✅ Working |

---

## 7. What Works (Proven)

### Absolutely Confirmed

1. **CSV data is correct**: All known puzzle keys verified against Bitcoin blockchain
2. **Cryptographic pipeline**: We can derive Bitcoin addresses from private keys
3. **Calibration 1-70**: With correct drift values, we get 100% accuracy
4. **Lane structure**: 16 independent lanes, little-endian byte order
5. **A coefficients**: [1, 91, 1, 1, 1, 169, 1, 1, 1, 32, 1, 1, 1, 182, 1, 1]

### Partially Confirmed

1. **PySR formula**: Claims 100% but needs independent verification
2. **Bridge prediction**: Multi-step formula works for 75→80 but not all bridges
3. **Neural network**: 91.39% accuracy (good for structure, not for prediction)

---

## 8. What Doesn't Work Yet

### Critical Failures

1. **Cannot predict puzzle 71**: No proven method to generate from puzzle 70
2. **Model contradiction**: PySR and Calibration models don't reconcile
3. **Bridge gaps**: Cannot fill 71-74, 76-79, etc. with confidence

### Open Questions

1. Why does PySR claim no drift but calibration requires drift?
2. Why do lanes 10-15 become non-zero after puzzle 80?
3. What is the true generating function?

---

## 9. Why We're Not Getting It Right

### Root Causes

1. **Claude is solving, not training**: We've been having Claude attempt solutions instead of training local AI to discover patterns

2. **Arbitrary ranges**: Testing on "60-70" or "last 10" instead of from the beginning

3. **Missing the structure**: We have pieces (A coefficients, drift patterns) but not the unified theory

4. **Not using bridges correctly**: Bridges should teach the AI about the structure, not just serve as endpoints

### The Insight

> "Training should make the network understand how the structure is BUILT, then start building the same. If it gets the same result as we have till 70, it should then get all the solutions naturally, since all this is engineered from scratch!"

This means:
- Start from puzzle 1
- Learn the construction rule
- Reproduce 1-70 exactly
- If successful, 71+ should follow naturally

---

## 10. The AI Orchestrator Approach

### What We Need

An **AI orchestrator** (local model like qwen2.5-coder) that:

1. **Has tools**: Neural network training, PySR symbolic regression, validation scripts
2. **Tests theories**: Proposes formulas, tests against data, refines
3. **Uses bridges**: Treats bridge puzzles as additional constraints/evidence
4. **Learns structure**: Discovers HOW the ladder was built, not just WHAT it produces

### Architecture

```
┌─────────────────────────────────────────────────────────┐
│                   AI ORCHESTRATOR                        │
│              (qwen2.5-coder or similar)                  │
├─────────────────────────────────────────────────────────┤
│                                                          │
│   ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │
│   │   PySR      │  │   Neural    │  │  Validator  │    │
│   │  Symbolic   │  │   Network   │  │   Suite     │    │
│   │ Regression  │  │  Training   │  │             │    │
│   └─────────────┘  └─────────────┘  └─────────────┘    │
│          │                │                │             │
│          └────────────────┼────────────────┘             │
│                           │                              │
│                    ┌──────┴──────┐                      │
│                    │   Theory    │                      │
│                    │  Generator  │                      │
│                    └──────┬──────┘                      │
│                           │                              │
│   ┌─────────────┐  ┌─────┴─────┐  ┌─────────────┐      │
│   │  Puzzles    │  │  Bridges  │  │  Crypto     │      │
│   │   1-70      │  │ 75,80,85  │  │ Validator   │      │
│   │   (known)   │  │   etc.    │  │             │      │
│   └─────────────┘  └───────────┘  └─────────────┘      │
│                                                          │
└─────────────────────────────────────────────────────────┘
```

### Workflow

1. **Propose theory**: AI proposes a formula (e.g., "X_{k+1} = X_k^2 mod 256")
2. **Train/test**: Use PySR or NN to fit/validate the theory
3. **Verify**: Check against known puzzles 1-70
4. **Check bridges**: Verify against bridges 75, 80, 85, 90, 95
5. **Refine or accept**: If 100% match, theory is proven; else refine

---

## 11. Training Strategy

### Phase 1: Reproduce Puzzles 1-70

**Goal**: Train AI to generate exact matches for puzzles 1-70

**Method**:
1. Start from puzzle 1 (seed)
2. Apply learned transformation
3. Compare output to puzzle 2
4. Iterate until perfect accuracy

**Success Metric**: 100% byte-for-byte match on all 69 transitions

### Phase 2: Validate on Bridges

**Goal**: Same model should predict bridges without modification

**Method**:
1. Take puzzle 70 (last known)
2. Apply transformation 5 times
3. Compare to puzzle 75
4. Repeat for 75→80, 80→85, etc.

**Success Metric**: 100% match on all bridges

### Phase 3: Generate Unknown Puzzles

**Goal**: Generate puzzles 71-74, 76-79, etc.

**Method**:
1. Apply transformation from puzzle 70
2. Generate 71, 72, 73, 74
3. Verify that puzzle 75 matches known bridge

**Success Metric**: Interpolated puzzles are consistent with bridge endpoints

### Phase 4: Extend to 160

**Goal**: Generate all puzzles up to 160

**Validation**: Compare any future solved puzzles against predictions

---

## 12. Tools the AI Needs

### Tool 1: PySR Symbolic Regression

**Purpose**: Discover mathematical formulas from data
**Input**: (X_k, lane) pairs
**Output**: Symbolic formula f(X_k, lane)
**Usage**: Find the transformation rule

### Tool 2: Neural Network Training

**Purpose**: Learn patterns that may not be expressible symbolically
**Input**: Training data (puzzles 1-70)
**Output**: Trained model that predicts X_{k+1} from X_k
**Usage**: Pattern recognition, structure discovery

### Tool 3: Validation Suite

**Purpose**: Test any proposed formula against known data
**Input**: Formula + puzzles 1-70 + bridges
**Output**: Accuracy report (must be 100%)
**Usage**: Accept/reject theories

### Tool 4: Cryptographic Validator

**Purpose**: Verify generated keys produce correct Bitcoin addresses
**Input**: Private key (hex)
**Output**: Bitcoin address
**Usage**: Final proof that generated keys are valid

### Tool 5: Bridge Analyzer

**Purpose**: Use bridges to constrain and validate theories
**Input**: Bridge puzzles (75, 80, 85, 90, 95)
**Output**: Constraints on the formula (e.g., "5-step prediction must match")
**Usage**: Multi-step validation

---

## 13. Success Criteria

### Minimum Viable Success

1. ✅ 100% accuracy on puzzles 1-70
2. ✅ 100% accuracy on bridges (75, 80, 85, 90, 95)
3. ✅ Single unified formula (not lookup table)
4. ✅ Can generate puzzles 71-74, 76-79, etc.

### Full Success

1. All minimum criteria
2. Formula is mathematically interpretable
3. Can predict puzzles up to 160
4. Bitcoin addresses validate correctly

### Proof of Discovery

When the AI discovers the true formula:
1. It can reproduce all known data exactly
2. It can generate unknown puzzles
3. The formula makes mathematical sense
4. Independent verification succeeds

---

## 14. Action Items

### Immediate (Today)

- [ ] Reconcile Model A (PySR) and Model B (Calibration)
- [ ] Test PySR formula independently on bridges
- [ ] Document the byte order (little-endian) confusion clearly
- [ ] Create unified test suite that tests ANY proposed formula

### Short-term (This Week)

- [ ] Set up AI orchestrator framework
- [ ] Integrate PySR as a callable tool
- [ ] Integrate neural network training as a callable tool
- [ ] Create theory proposal → test → refine loop

### Medium-term (This Month)

- [ ] Train AI to reproduce puzzles 1-70 from scratch
- [ ] Validate on all bridges
- [ ] Generate missing puzzles (71-74, 76-79, etc.)
- [ ] Full cryptographic validation

### Long-term

- [ ] Extend to puzzle 160
- [ ] Document the complete discovery
- [ ] Publish findings (defensive research)

---

## Appendix A: File Locations

### Key Directories

```
/home/solo/LadderV3/kh-assist/
├── data/
│   └── btc_puzzle_1_160_full.csv      # Source truth
├── db/
│   └── kh.db                           # SQLite database
├── out/
│   └── ladder_calib_CORRECTED.json    # Working calibration
├── experiments/
│   ├── 01-pysr-symbolic-regression/   # PySR discovery
│   ├── 02-transformer-sequence/       # Neural network approach
│   ├── 03-lstm-recurrent/             # LSTM approach
│   ├── 04-reasoning-hybrid/           # Hybrid reasoning
│   └── 05-ai-learns-ladder/           # Current experiment
└── tools/                              # Utility scripts
```

### Key Files

| File | Purpose |
|------|---------|
| `CLAUDE.md` | Project overview for Claude |
| `last_status.md` | Current session status |
| `20251202TODO.md` | This document |
| `out/ladder_calib_CORRECTED.json` | 100% accurate calibration |

---

## Appendix B: The Formulas

### Formula 1: PySR (Polynomial)

```python
X_{k+1}[lane] = X_k[lane]^exponent[lane] mod 256

exponents = [3, 2, 3, 2, 2, 3, 0, 2, 2, 3, 3, 2, 2, 2, 2, 3]
```

### Formula 2: Calibration (Affine)

```python
X_{k+1}[lane] = (A[lane]^4 * X_k[lane] + drift[k][lane]) mod 256

A = [1, 91, 1, 1, 1, 169, 1, 1, 1, 32, 1, 1, 1, 182, 1, 1]
drift = per-transition values from calibration file
```

### Relationship (To Be Discovered)

If both formulas produce the same results, they must be mathematically equivalent. The AI orchestrator should discover this relationship.

---

## Appendix C: Quick Commands

### Verify Current Calibration

```bash
cd /home/solo/LadderV3/kh-assist/experiments/05-ai-learns-ladder
python3 validate_full_process.py | tail -20
```

### Test PySR Formula

```bash
cd /home/solo/LadderV3/kh-assist/experiments/01-pysr-symbolic-regression
python3 scripts/verify_against_bitcoin_keys.py
```

### Load Calibration in Python

```python
import json
with open('out/ladder_calib_CORRECTED.json') as f:
    calib = json.load(f)
A = [calib['A'][str(i)] for i in range(16)]
print(f"A coefficients: {A}")
```

---

## Appendix D: Philosophy Reminders

1. **This is engineering, not brute force**: There's a formula to discover
2. **Start from puzzle 1**: Don't pick arbitrary ranges
3. **Train, don't solve**: Claude documents and trains; local AI discovers
4. **Bridges are teachers**: Use them to validate understanding, not just as endpoints
5. **100% or nothing**: Partial accuracy means wrong formula

---

**Document Status**: Living document, update as progress is made
**Last Updated**: 2025-12-02
**Next Action**: Reconcile the two competing models

---

*"The ladder was engineered. The formula exists. Train the AI to discover it."*
